{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# NOTE: you CAN change this cell\n",
        "# If you want to use your own database, download it here\n",
        "!gdown --fuzzy https://drive.google.com/file/d/16DjApJs5CMpTh5FySV7Qok8JA95dWs94/view?usp=sharing -O file.json"
      ],
      "metadata": {
        "id": "i20WfB6lqiUy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d431475-c001-436f-e2b4-6c9a33e247c2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16DjApJs5CMpTh5FySV7Qok8JA95dWs94\n",
            "To: /content/file.json\n",
            "\r  0% 0.00/2.11M [00:00<?, ?B/s]\r100% 2.11M/2.11M [00:00<00:00, 66.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: you CAN change this cell\n",
        "# Add more to your needs\n",
        "# you must place ALL pip install here\n",
        "!pip install editdistance\n",
        "!pip install numpy"
      ],
      "metadata": {
        "id": "J8znFuZTzwoS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fa69ca9-68ff-48d1-bf11-2d255e29f3d9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (0.6.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: you CAN change this cell\n",
        "# import your library here\n",
        "import time\n",
        "import numpy as np\n",
        "import editdistance\n",
        "import math\n",
        "import json\n",
        "import re\n"
      ],
      "metadata": {
        "id": "AodaIxYa32hT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: you MUST change this cell\n",
        "# New methods / functions must be written under class Solution.\n",
        "class Solution:\n",
        "    def __init__(self):\n",
        "        # list provice, district, ward for private test, do not change for any reason\n",
        "        self.province_path = 'list_province.txt'\n",
        "        self.district_path = 'list_district.txt'\n",
        "        self.ward_path = 'list_ward.txt'\n",
        "\n",
        "        # write your preprocess here, add more method if needed\n",
        "        class BM25:\n",
        "            def __init__(self, k1=1.5, b=0.75):\n",
        "                self.k1 = k1\n",
        "                self.b = b\n",
        "                self.tf = []\n",
        "                self.df = {}\n",
        "                self.idf = {}\n",
        "                self.doc_len = []\n",
        "                self.corpus_size = 0\n",
        "                self.avg_doc_len = 0\n",
        "                self.corpus = []\n",
        "\n",
        "            def fit(self, corpus):\n",
        "                self.corpus = corpus\n",
        "                self._compute_corpus_stats()\n",
        "                return self\n",
        "\n",
        "            def search(self, query):\n",
        "                scores = []\n",
        "                for index in range(self.corpus_size):\n",
        "                    scores.append(self._score(query, index))\n",
        "                return scores\n",
        "\n",
        "            def _compute_corpus_stats(self):\n",
        "                for document in self.corpus:\n",
        "                    self.corpus_size += 1\n",
        "                    self.doc_len.append(len(document))\n",
        "                    frequencies = {}\n",
        "                    for term in document:\n",
        "                        term_count = frequencies.get(term, 0) + 1\n",
        "                        frequencies[term] = term_count\n",
        "                    self.tf.append(frequencies)\n",
        "                    for term in frequencies:\n",
        "                        self.df[term] = self.df.get(term, 0) + 1\n",
        "                for term, freq in self.df.items():\n",
        "                    self.idf[term] = math.log(1 + (self.corpus_size - freq + 0.5) / (freq + 0.5))\n",
        "                self.avg_doc_len = sum(self.doc_len) / self.corpus_size\n",
        "\n",
        "            def _score(self, query, index):\n",
        "                score = 0.0\n",
        "                doc_len = self.doc_len[index]\n",
        "                frequencies = self.tf[index]\n",
        "\n",
        "                for term in query:\n",
        "                    if term in frequencies:\n",
        "                        freq = frequencies[term]\n",
        "                        numerator = self.idf[term] * freq * (self.k1 + 1)\n",
        "                        denominator = freq + self.k1 * (1 - self.b + self.b * doc_len / self.avg_doc_len)\n",
        "                        score += numerator / denominator\n",
        "\n",
        "                return score\n",
        "\n",
        "        self.k = 5\n",
        "        self.threshold = 2\n",
        "        self.addresses = []\n",
        "        self.stop_word = ['thị trấn', 'quận', 'tỉnh', 'tp', 'xã', 'thị xã', 'thành phố', 'x ', 'thị trấn', 'q ', 'huyện', 'f', 'tt', 'tx', 'phường', ' t ', 'tnh', ' h ',',','.']\n",
        "        # Load our dataset\n",
        "        with open(\"/content/file.json\") as f:\n",
        "              json_data = f.read()\n",
        "              data = json.loads(json_data)\n",
        "              text = []\n",
        "              for address in data:\n",
        "                  full = json.loads(address)['full_address']\n",
        "                  self.addresses.append(eval(address))\n",
        "\n",
        "                  for rm in self.stop_word:\n",
        "                     full = full.replace(rm, \" \")\n",
        "                  txt = []\n",
        "                  for item in full.split(\" \"):\n",
        "                     if item == \"\":\n",
        "                        continue\n",
        "                     else:\n",
        "                        txt.append(item)\n",
        "                  text.append(txt)\n",
        "\n",
        "        self.bm25 = BM25()\n",
        "        self.bm25.fit(text)\n",
        "\n",
        "    def get_best(self, query,text, k=5):\n",
        "        scores = self.bm25.search(query)\n",
        "        scores_index = np.argsort(scores)[::-1]\n",
        "        top_results = np.array([self.addresses[i] for i in scores_index][:k])\n",
        "\n",
        "        # Calculate edit distance for each result and select the one with the smallest distance\n",
        "        final_result = min(top_results, key=lambda result: editdistance.eval(result['full_address'].replace(\",\",\"\"), text))\n",
        "        return final_result\n",
        "\n",
        "\n",
        "    def process(self, s: str):\n",
        "        text, query = self.preprocess(s)\n",
        "        result = self.get_best( query,text, k=5)\n",
        "        result = self.postprocess(text, result)\n",
        "        return result\n",
        "\n",
        "    def detect_quan_huyen(self, text):\n",
        "        quan_huyen = []\n",
        "        i = 0\n",
        "        while i < len(text) - 1:\n",
        "            if text[i].upper() in 'QXHTP' and text[i+1] in 'BCDFGHJKLMNPQRSTVWXYZAĂÂEÊIOÔƠUƯY0123456789':\n",
        "                quan_huyen.append(text[i:i+2])\n",
        "                i += 2\n",
        "            else:\n",
        "                i += 1\n",
        "        return [item for item in quan_huyen if item not in [\"TP\", \"TT\", \"TX\"]]\n",
        "\n",
        "    def preprocess(self, text: str):\n",
        "        t = self.detect_quan_huyen(text)\n",
        "        replace_dict = {temp: f\"{temp[0]} {temp[1]}\" for temp in t}\n",
        "\n",
        "        for char, replacement in replace_dict.items():\n",
        "            text = text.replace(char, replacement)\n",
        "\n",
        "        text = text.lower()\n",
        "\n",
        "        rm = ['thị trấn', 'quận', 'tỉnh', 'tp', 'xã', 'thị xã', 'thành phố', 'x ', 'thị trấn', 'q ', 'huyện', 'f', 'tt', 'tx', 'phường', ' t ', 'tnh', ' h ',',','.']\n",
        "\n",
        "\n",
        "        for r in rm:\n",
        "            text = text.replace(r, \" \")\n",
        "\n",
        "        query = [item.strip() for item in text.split(\" \") if item != \"\"]\n",
        "\n",
        "        return text, query\n",
        "\n",
        "    def util_edit_distance(self, text, name):\n",
        "        similar_word = None\n",
        "        min_distance = float('inf')\n",
        "\n",
        "        for i in range(len(text) - len(name) + 1):\n",
        "            res_string = text[i:i + len(name)]\n",
        "            distance = editdistance.eval(res_string, name)\n",
        "\n",
        "            if distance <= self.threshold and distance < min_distance:\n",
        "                similar_word = res_string\n",
        "                min_distance = distance\n",
        "\n",
        "        return similar_word\n",
        "\n",
        "    def remove_address_component(self, text, component):\n",
        "        if component in text:\n",
        "            return text.replace(component, \"\", 1)\n",
        "        return text\n",
        "\n",
        "    def postprocess(self, text: str, best_result):\n",
        "        levels = [\"province\", \"district\", \"ward\"]\n",
        "        for level in levels:\n",
        "            name = best_result[level].lower()\n",
        "            if name == \"\":\n",
        "                continue\n",
        "\n",
        "            if name in text:\n",
        "                text = self.remove_address_component(text, name)\n",
        "            else:\n",
        "                same = self.util_edit_distance(text, name)\n",
        "                if same:\n",
        "                    text = self.remove_address_component(text, same)\n",
        "                else:\n",
        "                    best_result[level] = \"\"\n",
        "\n",
        "        return best_result\n",
        "\n"
      ],
      "metadata": {
        "id": "xtwG3tBDzMLD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: DO NOT change this cell\n",
        "# This cell is for downloading private test\n",
        "!rm -rf test.json\n",
        "!gdown --fuzzy https://drive.google.com/file/d/1PBt3U9I3EH885CDhcXspebyKI5Vw6uLB/view?usp=sharing -O test.json"
      ],
      "metadata": {
        "id": "7Sdb3ddTr1Jz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0ca4011-8ad9-40f2-ac6c-d6cd9ad5beda"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PBt3U9I3EH885CDhcXspebyKI5Vw6uLB\n",
            "To: /content/test.json\n",
            "\r  0% 0.00/79.4k [00:00<?, ?B/s]\r100% 79.4k/79.4k [00:00<00:00, 70.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: DO NOT change this cell\n",
        "# This cell is for scoring\n",
        "\n",
        "TEAM_NAME = 'GROUP_1'  # This should be your team name\n",
        "EXCEL_FILE = f'{TEAM_NAME}.xlsx'\n",
        "\n",
        "import json\n",
        "import time\n",
        "with open('test.json') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "summary_only = True\n",
        "df = []\n",
        "solution = Solution()\n",
        "timer = []\n",
        "correct = 0\n",
        "for test_idx, data_point in enumerate(data):\n",
        "    address = data_point[\"text\"]\n",
        "\n",
        "    ok = 0\n",
        "    try:\n",
        "        start = time.perf_counter_ns()\n",
        "        result = solution.process(address)\n",
        "        answer = data_point[\"result\"]\n",
        "        finish = time.perf_counter_ns()\n",
        "        timer.append(finish - start)\n",
        "        ok += int(answer[\"province\"] == result[\"province\"])\n",
        "        ok += int(answer[\"district\"] == result[\"district\"])\n",
        "        ok += int(answer[\"ward\"] == result[\"ward\"])\n",
        "        df.append([\n",
        "            test_idx,\n",
        "            address,\n",
        "            answer[\"province\"],\n",
        "            result[\"province\"],\n",
        "            int(answer[\"province\"] == result[\"province\"]),\n",
        "            answer[\"district\"],\n",
        "            result[\"district\"],\n",
        "            int(answer[\"district\"] == result[\"district\"]),\n",
        "            answer[\"ward\"],\n",
        "            result[\"ward\"],\n",
        "            int(answer[\"ward\"] == result[\"ward\"]),\n",
        "            ok,\n",
        "            timer[-1] / 1_000_000_000,\n",
        "        ])\n",
        "    except Exception as e:\n",
        "        df.append([\n",
        "            test_idx,\n",
        "            address,\n",
        "            answer[\"province\"],\n",
        "            \"EXCEPTION\",\n",
        "            0,\n",
        "            answer[\"district\"],\n",
        "            \"EXCEPTION\",\n",
        "            0,\n",
        "            answer[\"ward\"],\n",
        "            \"EXCEPTION\",\n",
        "            0,\n",
        "            0,\n",
        "            0,\n",
        "        ])\n",
        "        # any failure count as a zero correct\n",
        "        pass\n",
        "    correct += ok\n",
        "\n",
        "\n",
        "    if not summary_only:\n",
        "        # responsive stuff\n",
        "        print(f\"Test {test_idx:5d}/{len(data):5d}\")\n",
        "        print(f\"Correct: {ok}/3\")\n",
        "        print(f\"Time Executed: {timer[-1] / 1_000_000_000:.4f}\")\n",
        "\n",
        "\n",
        "print(f\"-\"*30)\n",
        "total = len(data) * 3\n",
        "score_scale_10 = round(correct / total * 10, 2)\n",
        "if len(timer) == 0:\n",
        "    timer = [0]\n",
        "max_time_sec = round(max(timer) / 1_000_000_000, 4)\n",
        "avg_time_sec = round((sum(timer) / len(timer)) / 1_000_000_000, 4)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df2 = pd.DataFrame(\n",
        "    [[correct, total, score_scale_10, max_time_sec, avg_time_sec]],\n",
        "    columns=['correct', 'total', 'score / 10', 'max_time_sec', 'avg_time_sec',],\n",
        ")\n",
        "\n",
        "columns = [\n",
        "    'ID',\n",
        "    'text',\n",
        "    'province',\n",
        "    'province_student',\n",
        "    'province_correct',\n",
        "    'district',\n",
        "    'district_student',\n",
        "    'district_correct',\n",
        "    'ward',\n",
        "    'ward_student',\n",
        "    'ward_correct',\n",
        "    'total_correct',\n",
        "    'time_sec',\n",
        "]\n",
        "\n",
        "df = pd.DataFrame(df)\n",
        "df.columns = columns\n",
        "\n",
        "print(f'{TEAM_NAME = }')\n",
        "print(f'{EXCEL_FILE = }')\n",
        "print(df2)\n",
        "\n",
        "!pip install xlsxwriter\n",
        "writer = pd.ExcelWriter(EXCEL_FILE, engine='xlsxwriter')\n",
        "df2.to_excel(writer, index=False, sheet_name='summary')\n",
        "df.to_excel(writer, index=False, sheet_name='details')\n",
        "writer.close()\n"
      ],
      "metadata": {
        "id": "hjO6FFcA0DYi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c34c36da-0da6-443e-9b09-8d863ab4a23b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------\n",
            "TEAM_NAME = 'GROUP_1'\n",
            "EXCEL_FILE = 'GROUP_1.xlsx'\n",
            "   correct  total  score / 10  max_time_sec  avg_time_sec\n",
            "0     1092   1350        8.09        0.0795         0.021\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.2.0\n"
          ]
        }
      ]
    }
  ]
}